@article{HS13,
  title={Mesh denoising via L 0 minimization},
  author={He, Lei and Schaefer, Scott},
  journal={ACM Transactions on Graphics (TOG)},
  volume={32},
  number={4},
  pages={64},
  year={2013},
  publisher={ACM}
}

@inproceedings{FDC03,
  title={Bilateral mesh denoising},
  author={Fleishman, Shachar and Drori, Iddo and Cohen-Or, Daniel},
  booktitle={ACM transactions on graphics (TOG)},
  volume={22},
  number={3},
  pages={950--953},
  year={2003},
  organization={ACM}
}

@inproceedings{JDD03,
  title={Non-iterative, feature-preserving mesh smoothing},
  author={Jones, Thouis R and Durand, Fr{\'e}do and Desbrun, Mathieu},
  booktitle={ACM Transactions on Graphics (TOG)},
  volume={22},
  number={3},
  pages={943--949},
  year={2003},
  organization={ACM}
}

@article{SRML07,
  title={Fast and effective feature-preserving mesh denoising},
  author={Sun, Xianfang and Rosin, Paul and Martin, Ralph and Langbein, Frank},
  journal={IEEE transactions on visualization and computer graphics},
  volume={13},
  number={5},
  pages={925--938},
  year={2007},
  publisher={IEEE}
}

@article{ZFAT11,
  title={Bilateral normal filtering for mesh denoising},
  author={Zheng, Youyi and Fu, Hongbo and Au, Oscar Kin-Chung and Tai, Chiew-Lan},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={17},
  number={10},
  pages={1521--1530},
  year={2011},
  publisher={IEEE}
}

@inproceedings{ZDZBL15,
  title={Guided mesh normal filtering},
  author={Zhang, Wangyu and Deng, Bailin and Zhang, Juyong and Bouaziz, Sofien and Liu, Ligang},
  booktitle={Computer Graphics Forum},
  volume={34},
  number={7},
  pages={23--34},
  year={2015},
  organization={Wiley Online Library}
}

@article{YRP16,
  title={Mesh denoising based on normal voting tensor and binary optimization},
  author={Yadav, SK and Reitebuch, Ulrich and Polthier, Konrad},
  journal={arXiv preprint arXiv:1607.07427},
  year={2016}
}





@article{CNNS1,
    title={Convolutional neural networks in medical image understanding: a survey},
    author={D. R. Sarvamangala1, Raghavendra V. Kulkarni2},
    publisher={Springer},
    year={2021}

}


@misc{PWC1,
    title={PwC’s Global Artificial Intelligence Study: Exploiting the AI Revolution},
    author={PWC},
    url={https://www.pwc.com/gx/en/issues/data-and-analytics/publications/artificial-intelligence-study.html},
    year={2017}
}

@article{IST1,
    title={Como a Inteligência Artificial vai cuidar da sua Saúde},
    author={SALOMÃO FILHO},
    url={https://www.istoedinheiro.com.br/como-a-inteligencia-artificial-vai-cuidar-da-sua-saude/},
    year={2018}
}

@article{MIT1,
    title={Using AI to predict breast cancer and personalize care},
    year={2019},
    author={Adam Conner-Simons, Rachel Gordon},
    url={https://news.mit.edu/2019/using-ai-predict-breast-cancer-and-personalize-care-0507},
    publisher={Massachusetts Institute of Technology}

}

@misc{IBM1,
    title={What is artificial intelligence in medicine?},
    url={https://www.ibm.com/topics/artificial-intelligence-medicine#:~:text=How\%20is\%20artificial\%20intelligence\%20used,health\%20outcomes\%20and\%20patient\%20experiences},
    publisher={IBM},
    author={IBM},
    year={Acessado em 23/06/2023}
}

@misc{HARV1,
    title = {How Artificial Intelligence is Revolutionizing Drug Discovery},
    url={https://blog.petrieflom.law.harvard.edu/2023/03/20/how-artificial-intelligence-is-revolutionizing-drug-discovery/#:~:text=De%20novo%20drug%20design%3A%20While,drug%20molecules%20entirely%20from%20scratch.},
    publisher={Bill and Health},
    author={MATTHEW CHUN},
    year={2023},
    month={Março}
    
}


@dataset{Kermany2018,
  author       = {Daniel S. Kermany and Kang Zhang and Michael Goldbaum},
  title        = {Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification},
  year         = 2018,
  publisher    = {Mendeley Data},
  version      = {v2},
  doi          = {10.17632/rscbjbr9sj.2},
  url          = {https://dx.doi.org/10.17632/RSCBJBR9SJ.2}
}









-------------------------------------- NO CITE -----------------------------------------------
@ARTICLE{7422082,
  author={Anthimopoulos, Marios and Christodoulidis, Stergios and Ebner, Lukas and Christe, Andreas and Mougiakakou, Stavroula},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network}, 
  year={2016},
  volume={35},
  number={5},
  pages={1207-1216},
  doi={10.1109/TMI.2016.2535865}}

@ARTICLE{7404285,
  author={Brosch, Tom and Tang, Lisa Y. W. and Yoo, Youngjin and Li, David K. B. and Traboulsee, Anthony and Tam, Roger},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Deep 3D Convolutional Encoder Networks With Shortcuts for Multiscale Feature Integration Applied to Multiple Sclerosis Lesion Segmentation}, 
  year={2016},
  volume={35},
  number={5},
  pages={1229-1239},
  doi={10.1109/TMI.2016.2528821}}
@article{doi:10.1148/ryai.2019180015,
author = {Rayan, Jesse                         C. and Reddy, Nakul and Kan, J.                         Herman and Zhang, Wei and Annapragada, Ananth},
title = {Binomial Classification of Pediatric Elbow Fractures Using a Deep                     Learning Multiview Approach Emulating Radiologist Decision                     Making},
journal = {Radiology: Artificial Intelligence},
volume = {1},
number = {1},
pages = {e180015},
year = {2019},
doi = {10.1148/ryai.2019180015},
    note ={PMID: 33937781},

URL = { 
    
        https://doi.org/10.1148/ryai.2019180015
    
    

},
eprint = { 
    
        https://doi.org/10.1148/ryai.2019180015
    
    

}
,
    abstract = { Purpose To determine the feasibility of using deep learning with a multiview approach, similar to how a human radiologist reviews multiple images, for binomial classification of acute pediatric elbow radiographic abnormalities. Materials and Methods A total of 21 456 radiographic studies containing 58 817 images of the elbow and associated radiology reports over the course of a 4-year period from January 2014 through December 2017 at a dedicated children’s hospital were retrospectively retrieved. Mean age was 7.2 years, and 43\% were female patients. The studies were binomially classified, based on the reports, as either positive or negative for acute or subacute traumatic abnormality. The studies were randomly divided into a training set containing 20 350 studies and a validation set containing the remaining 1106 studies. A multiview approach was used for the model by combining both a convolutional neural network and recurrent neural network to interpret an entire series of three radiographs together. Sensitivity, specificity, positive predictive value, negative predictive value, area under the receiver operating characteristic curve (AUC), and their 95\% confidence intervals were calculated. Results AUC was 0.95, and accuracy was 88\% for the model on the studied dataset. Sensitivity for the model was 91\% (536 of 590), while the specificity for the model was 84\% (434 of 516). Of 241 supracondylar fractures, one was missed. Of 88 lateral condylar fractures, one was missed. Of 77 elbow effusions without fracture, 15 were missed. Of 184 other abnormalities, 37 were missed. Conclusion Deep learning can effectively classify acute and nonacute pediatric elbow abnormalities on radiographs in the setting of trauma. A recurrent neural network was used to classify an entire radiographic series, arrive at a decision based on all views, and identify fractures in pediatric patients with variable skeletal immaturity. Keywords: Computer Applications-Detection/Diagnosis, Elbow, Informatics, Technology Assessment © RSNA, 2019 Supplemental material is available for this article. }
}

@INPROCEEDINGS{7950512,
  author={Dasgupta, Avijit and Singh, Sonam},
  booktitle={2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)}, 
  title={A fully convolutional neural network based structured prediction approach towards the retinal vessel segmentation}, 
  year={2017},
  volume={},
  number={},
  pages={248-251},
  doi={10.1109/ISBI.2017.7950512}}






@article{doi:10.1080/21681163.2015.1124249,
author = {Mingchen Gao, Ulas Bagci, Le Lu, Aaron Wu, Mario Buty, Hoo-Chang Shin, Holger Roth, Georgios Z. Papadakis, Adrien Depeursinge, Ronald M. Summers, Ziyue Xu and Daniel J. Mollura},
title = {Holistic classification of CT attenuation patterns for interstitial lung diseases via deep convolutional neural networks},
journal = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging \& Visualization},
volume = {6},
number = {1},
pages = {1-6},
year = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/21681163.2015.1124249},

    note ={PMID: 29623248},


URL = { 
    
        https://doi.org/10.1080/21681163.2015.1124249
    
    

},
eprint = { 
    
        https://doi.org/10.1080/21681163.2015.1124249
    
    

}

}



@article{Hesamian_Jia_He_Kennedy_2019, title={Deep learning techniques for medical image segmentation: Achievements and challenges}, volume={32}, DOI={10.1007/s10278-019-00227-x}, number={4}, journal={Journal of Digital Imaging}, author={Hesamian, Mohammad Hesam and Jia, Wenjing and He, Xiangjian and Kennedy, Paul}, year={2019}, pages={582–596}} 


@article{Gao_Han_Li_Ji_Zhang_Sun_2018, title={Image super-resolution based on two-level residual learning CNN}, volume={79}, DOI={10.1007/s11042-018-6751-5}, number={7–8}, journal={Multimedia Tools and Applications}, author={Gao, Min and Han, Xian-Hua and Li, Jing and Ji, Hui and Zhang, Huaxiang and Sun, Jiande}, year={2018}, pages={4831–4846}} 


@ARTICLE{7412749,
  author={Kallenberg, Michiel and Petersen, Kersten and Nielsen, Mads and Ng, Andrew Y. and Diao, Pengfei and Igel, Christian and Vachon, Celine M. and Holland, Katharina and Winkel, Rikke Rass and Karssemeijer, Nico and Lillholm, Martin},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Unsupervised Deep Learning Applied to Breast Density Segmentation and Mammographic Risk Scoring}, 
  year={2016},
  volume={35},
  number={5},
  pages={1322-1331},
  doi={10.1109/TMI.2016.2532122}}

@ARTICLE{7501527,
  author={Ince, Turker and Kiranyaz, Serkan and Eren, Levent and Askar, Murat and Gabbouj, Moncef},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Real-Time Motor Fault Detection by 1-D Convolutional Neural Networks}, 
  year={2016},
  volume={63},
  number={11},
  pages={7067-7075},
  doi={10.1109/TIE.2016.2582729}}


@ARTICLE{6975210,
  author={Menze, Bjoern H. and Jakab, Andras and Bauer, Stefan and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Kirby, Justin and Burren, Yuliya and Porz, Nicole and Slotboom, Johannes and Wiest, Roland and Lanczi, Levente and Gerstner, Elizabeth and Weber, Marc-André and Arbel, Tal and Avants, Brian B. and Ayache, Nicholas and Buendia, Patricia and Collins, D. Louis and Cordier, Nicolas and Corso, Jason J. and Criminisi, Antonio and Das, Tilak and Delingette, Hervé and Demiralp, Çağatay and Durst, Christopher R. and Dojat, Michel and Doyle, Senan and Festa, Joana and Forbes, Florence and Geremia, Ezequiel and Glocker, Ben and Golland, Polina and Guo, Xiaotao and Hamamci, Andac and Iftekharuddin, Khan M. and Jena, Raj and John, Nigel M. and Konukoglu, Ender and Lashkari, Danial and Mariz, José António and Meier, Raphael and Pereira, Sérgio and Precup, Doina and Price, Stephen J. and Raviv, Tammy Riklin and Reza, Syed M. S. and Ryan, Michael and Sarikaya, Duygu and Schwartz, Lawrence and Shin, Hoo-Chang and Shotton, Jamie and Silva, Carlos A. and Sousa, Nuno and Subbanna, Nagesh K. and Szekely, Gabor and Taylor, Thomas J. and Thomas, Owen M. and Tustison, Nicholas J. and Unal, Gozde and Vasseur, Flor and Wintermark, Max and Ye, Dong Hye and Zhao, Liang and Zhao, Binsheng and Zikic, Darko and Prastawa, Marcel and Reyes, Mauricio and Van Leemput, Koen},
  journal={IEEE Transactions on Medical Imaging}, 
  title={The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)}, 
  year={2015},
  volume={34},
  number={10},
  pages={1993-2024},
  doi={10.1109/TMI.2014.2377694}}


@ARTICLE{7444155,
  author={Moeskops, Pim and Viergever, Max A. and Mendrik, Adriënne M. and de Vries, Linda S. and Benders, Manon J. N. L. and Išgum, Ivana},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Automatic Segmentation of MR Brain Images With a Convolutional Neural Network}, 
  year={2016},
  volume={35},
  number={5},
  pages={1252-1261},
  doi={10.1109/TMI.2016.2548501}}


@INPROCEEDINGS{7590963,
  author={Nasr-Esfahani, E. and Samavi, S. and Karimi, N. and Soroushmehr, S.M.R. and Jafari, M.H. and Ward, K. and Najarian, K.},
  booktitle={2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Melanoma detection by analysis of clinical images using convolutional neural network}, 
  year={2016},
  volume={},
  number={},
  pages={1373-1376},
  doi={10.1109/EMBC.2016.7590963}}


@article{AREVALO2016248,
title = {Representation learning for mammography mass lesion classification with convolutional neural networks},
journal = {Computer Methods and Programs in Biomedicine},
volume = {127},
pages = {248-257},
year = {2016},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2015.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0169260715300110},
author = {John Arevalo and Fabio A. González and Raúl Ramos-Pollán and Jose L. Oliveira and Miguel Angel {Guevara Lopez}},
keywords = {Breast cancer, Feature learning, Convolutional neural networks, Computer-aided diagnosis, Mammography},
abstract = {Background and objective
The automatic classification of breast imaging lesions is currently an unsolved problem. This paper describes an innovative representation learning framework for breast cancer diagnosis in mammography that integrates deep learning techniques to automatically learn discriminative features avoiding the design of specific hand-crafted image-based feature detectors.
Methods
A new biopsy proven benchmarking dataset was built from 344 breast cancer patients’ cases containing a total of 736 film mammography (mediolateral oblique and craniocaudal) views, representative of manually segmented lesions associated with masses: 426 benign lesions and 310 malignant lesions. The developed method comprises two main stages: (i) preprocessing to enhance image details and (ii) supervised training for learning both the features and the breast imaging lesions classifier. In contrast to previous works, we adopt a hybrid approach where convolutional neural networks are used to learn the representation in a supervised way instead of designing particular descriptors to explain the content of mammography images.
Results
Experimental results using the developed benchmarking breast cancer dataset demonstrated that our method exhibits significant improved performance when compared to state-of-the-art image descriptors, such as histogram of oriented gradients (HOG) and histogram of the gradient divergence (HGD), increasing the performance from 0.787 to 0.822 in terms of the area under the ROC curve (AUC). Interestingly, this model also outperforms a set of hand-crafted features that take advantage of additional information from segmentation by the radiologist. Finally, the combination of both representations, learned and hand-crafted, resulted in the best descriptor for mass lesion classification, obtaining 0.826 in the AUC score.
Conclusions
A novel deep learning based framework to automatically address classification of breast mass lesions in mammography was developed.}
}


@ARTICLE{7426413,
  author={Pereira, Sérgio and Pinto, Adriano and Alves, Victor and Silva, Carlos A.},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images}, 
  year={2016},
  volume={35},
  number={5},
  pages={1240-1251},
  doi={10.1109/TMI.2016.2538465}}



@InProceedings{pmlr-v136-phillips20a,
  title = 	 {CheXphoto: 10,000+ Photos and Transformations of Chest X-rays for Benchmarking Deep Learning Robustness},
  author =       {Phillips, Nick A. and Rajpurkar, Pranav and Sabini, Mark and Krishnan, Rayan and Zhou, Sharon and Pareek, Anuj and Phu, Nguyet Minh and Wang, Chris and Jain, Mudit and Du, Nguyen Duong and Truong, Steven QH and Ng, Andrew Y. and Lungren, Matthew P.},
  booktitle = 	 {Proceedings of the Machine Learning for Health NeurIPS Workshop},
  pages = 	 {318--327},
  year = 	 {2020},
  editor = 	 {Alsentzer, Emily and McDermott, Matthew B. A. and Falck, Fabian and Sarkar, Suproteem K. and Roy, Subhrajit and Hyland, Stephanie L.},
  volume = 	 {136},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {11 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v136/phillips20a/phillips20a.pdf},
  url = 	 {https://proceedings.mlr.press/v136/phillips20a.html},
  abstract = 	 {Clinical deployment of deep learning algorithms for chest x-ray interpretation requires a solution that can integrate into the vast spectrum of clinical workflows across the world. An appealing approach to scaled deployment is to leverage the ubiquity of smartphones by capturing photos of x-rays to share with clinicians using messaging services like WhatsApp. However, the application of chest x-ray algorithms to photos of chest x-rays requires reliable classification in the presence of artifacts not typically encountered in digital x-rays used to train machine learning models. We introduce CheXphoto, a dataset of smartphone photos and synthetic photographic transformations of chest x-rays sampled from the CheXpert dataset. To generate CheXphoto we (1) automatically and manually captured photos of digital x-rays under different settings, and (2) generated synthetic transformations of digital x-rays targeted to make them look like photos of digital x-rays and x-ray films. We release this dataset as a resource for testing and improving the robustness of deep learning algorithms for automated chest x-ray interpretation on smartphone photos of chest x-rays.}
}


@misc{rajpurkar2017chexnet,
      title={CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning}, 
      author={Pranav Rajpurkar and Jeremy Irvin and Kaylie Zhu and Brandon Yang and Hershel Mehta and Tony Duan and Daisy Ding and Aarti Bagul and Curtis Langlotz and Katie Shpanskaya and Matthew P. Lungren and Andrew Y. Ng},
      year={2017},
      eprint={1711.05225},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@ARTICLE{7801947,
  author={Ravì, Daniele and Wong, Charence and Deligianni, Fani and Berthelot, Melissa and Andreu-Perez, Javier and Lo, Benny and Yang, Guang-Zhong},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Deep Learning for Health Informatics}, 
  year={2017},
  volume={21},
  number={1},
  pages={4-21},
  doi={10.1109/JBHI.2016.2636665}}


@INPROCEEDINGS{7545996,
  author={Ribeiro, Eduardo and Uhl, Andreas and Häfner, Michael},
  booktitle={2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)}, 
  title={Colonic Polyp Classification with Convolutional Neural Networks}, 
  year={2016},
  volume={},
  number={},
  pages={253-258},
  doi={10.1109/CBMS.2016.39}}


@article{SUN20174,
title = {Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data},
journal = {Computerized Medical Imaging and Graphics},
volume = {57},
pages = {4-9},
year = {2017},
note = {Recent Developments in Machine Learning for Medical Imaging Applications},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2016.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0895611116300696},
author = {Wenqing Sun and Tzu-Liang (Bill) Tseng and Jianying Zhang and Wei Qian},
keywords = {Semi-supervised learning, Deep learning, Computer aided diagnosis, Convolutional neural network, Unlabeled data},
abstract = {In this study we developed a graph based semi-supervised learning (SSL) scheme using deep convolutional neural network (CNN) for breast cancer diagnosis. CNN usually needs a large amount of labeled data for training and fine tuning the parameters, and our proposed scheme only requires a small portion of labeled data in training set. Four modules were included in the diagnosis system: data weighing, feature selection, dividing co-training data labeling, and CNN. 3158 region of interests (ROIs) with each containing a mass extracted from 1874 pairs of mammogram images were used for this study. Among them 100 ROIs were treated as labeled data while the rest were treated as unlabeled. The area under the curve (AUC) observed in our study was 0.8818, and the accuracy of CNN is 0.8243 using the mixed labeled and unlabeled data.}
}



@InProceedings{10.1007/978-3-319-10590-1_53,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}



%%%%%%%%%%%%%%%%%%%%% Introdução %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@article{Haque_2023, title={A Brief Analysis of “ChatGPT” – A Revolutionary Tool Designed by OpenAI}, volume={1}, url={https://publications.eai.eu/index.php/airo/article/view/2983}, DOI={10.4108/airo.v1i1.2983}, abstractNote={&amp;lt;p class=&amp;quot;ICST-abstracttext&amp;quot;&amp;gt;&amp;lt;span lang=&amp;quot;EN-GB&amp;quot;&amp;gt;The ChatGPT, a powerful conversational tool trained by OpenAI is considered to be a revolutionary model in the field of artificial intelligence and natural language processing. It has received a lot of attention because of its potential to automate a variety of tasks and possibly have an impact on sectors like translation, customer service, and content creation. It uses GPT-3 (Generative Pre-training Transformer 3) language model to process user queries. GPT-3 has been trained on a very large dataset, which includes a wide range of texts from the internet and other sources. This has given it a broad knowledge base and has allowed it to generate responses to a wide range of prompts that are coherent and human-like. GPT-3 is one of the largest and most powerful language models to date, and it has the ability to perform a wide range of natural language processing tasks. After its release, ChatGPT has become a trending tool for the public to experiment and explore what it is capable of. In this article, we want to clarify what ChatGPT is. How does it work? What makes it different from other chatbots or search engines like Google? What are the major challenges and future prospects for it?&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;}, journal={EAI Endorsed Transactions on AI and Robotics}, author={Haque, Md. Asraful}, year={2023}, month={Mar.}, pages={e15} }

@article{10.11648/j.epes.20221106.12,
  author = {Ghaeth Fandi and Miroslav Müller and Martin Čerňan and Zdeněk Müller and Josef Tlusty},
  title = {The Impact of Cyber Attack on Emergency Energy System},
  journal = {American Journal of Electrical Power and Energy Systems},
  volume = {11},
  number = {6},
  pages = {118-122},
  doi = {10.11648/j.epes.20221106.12},
  url = {https://doi.org/10.11648/j.epes.20221106.12},
  eprint = {https://download.sciencepg.com/pdf/10.11648.j.epes.20221106.12},
  abstract = {An emergency energy system is a backup power system used in critical situations with the aim of protecting lives and property from the consequences of energy loss, as is the case in hospitals (heart monitors, Ventilator,…etc), and also in sensitive facilities (military industries and government buildings). The emergency power system can contain batteries of all kinds, in addition to solar and wind energy equipment and other cheap types of energy. The concept of cyber security arose several decades after the invention of the computer. At first, there was no need for cyber security, as it was difficult for electronic attacks to occur, because access to computers was limited to specific numbers of users, as the devices were giant confined to a room with certain specifications and were not Linked to networks at the time, Energy sectors expose themselves to a range of cyber threats that can damage control systems. So management, engineering, and IT must adhere to a comprehensive approach that includes threat prevention, detection, and elimination. In this research we will try to mitigate the effects of the cyber attack on these systems by applying some algorithms in order to detect, identify and prevent such attacks, and we will see through the results we obtained that we have made remarkable progress in this field.},
 year = {2023}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Pesquisas realizadas %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{doi:10.2147/COPD.S140378,
author = {Filipe Froes, Nicolas Roche and Francesco Blasi},
title = {Pneumococcal vaccination and chronic respiratory diseases},
journal = {International Journal of Chronic Obstructive Pulmonary Disease},
volume = {12},
number = {},
pages = {3457-3468},
year = {2017},
publisher = {Dove Medical Press},
doi = {10.2147/COPD.S140378},

    note ={PMID: 29255353},
URL = {     
        https://www.tandfonline.com/doi/abs/10.2147/COPD.S140378
},
eprint = {    
        https://www.tandfonline.com/doi/pdf/10.2147/COPD.S140378
}

}

@online{WHO2023Pneumonia,
  author = {{World Health Organization}},
  title = {Pneumonia},
  year = {2023},
  url = {https://www.who.int/news-room/fact-sheets/detail/pneumonia#:~:text=Fran%C3%A7ais%20%D0%A0%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B9%20Espa%C3%B1ol%20Key%20facts,and%20by%20addressing%20environmental%20factors},
  urldate = {2023-11-17}
}

@misc{bvsmsDiaMundialPneumonia,
  title = {Dia Mundial da Pneumonia},
  howpublished = {\url{https://bvsms.saude.gov.br/12-11-dia-mundial-da-pneumonia/}},
  note = {Acessado em: 2023-11-17},
  year = {2023},
  author = {Ministério da Saúde do Brasil}
}

@misc{OurWorldInDataPneumonia,
  author = {Dadonaite, Bernadeta and Roser, Max},
  title = {Pneumonia},
  year = {2019},
  month = {11},
  howpublished = {\url{https://ourworldindata.org/pneumonia}},
  note = {Acessado em: 2023-11-17}
}




@misc{pneumoniaSymptoms,
  author = {Centers for Disease Control and Prevention},
  title = {Symptoms and Complications - Pneumococcal Disease},
  year = {2022},
  month = {05},
  howpublished = {\url{https://www.cdc.gov/pneumococcal/about/symptoms-complications.html}},
  note = {Acessado em: 2023-11-17}
}


@book{GoodfellowBengioCourville2016,
  title={Deep Learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT Press}
}


@ARTICLE{58337,
  author={Werbos, P.J.},
  journal={Proceedings of the IEEE}, 
  title={Backpropagation through time: what it does and how to do it}, 
  year={1990},
  volume={78},
  number={10},
  pages={1550-1560},
  doi={10.1109/5.58337}}


@book{Watt2016MachineLearning,
  title={Machine Learning Refined: Foundations, Algorithms, and Applications},
  author={Watt, Jeremy and Borhani, Reza and Katsaggelos, Aggelos K.},
  edition={2},
  year={2016},
  publisher={Cambridge University Press}
}

@article{gess2023convergence,
  title={Convergence rates for momentum stochastic gradient descent with noise of machine learning type},
  author={Gess, B. and Kassing, Sebastian},
  journal={arXiv preprint arXiv:2302.03550},
  year={2023},
  url={https://arxiv.org/abs/2302.03550}
}

@article{elshamy2023improving,
  title={Improving the efficiency of RMSProp optimizer by utilizing Nestrove in deep learning},
  author={Elshamy, Reham and Abu-Elnasr, O. and Elhoseny, M. and Elmougy, S.},
  journal={Scientific Reports},
  volume={13},
  number={1},
  year={2023},
  publisher={Nature Publishing Group},
  doi={10.1038/s41598-023-35663-x},
  url={https://www.nature.com/articles/s41598-023-35663-x}
}

@article{Sharma2022Enhanced,
  title={Enhanced Watershed Segmentation Algorithm-Based Modified ResNet50 Model for Brain Tumor Detection},
  author={Sharma, A. and Nandal, Amita and Dhaka, Arvind and Koundal, D. and Bogatinoska, D. C. and Alyami, H.},
  journal={BioMed Research International},
  volume={2022},
  pages={Article ID 7348344},
  year={2022},
  publisher={Hindawi},
  doi={10.1155/2022/7348344},
  url={https://downloads.hindawi.com/journals/bmri/2022/7348344.pdf}
}

@INPROCEEDINGS{7298594,
  author={Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Going deeper with convolutions}, 
  year={2015},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/CVPR.2015.7298594}}

@article{Szegedy2015RethinkingTI,
  title={Rethinking the Inception Architecture for Computer Vision},
  author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
  journal={arXiv: Computer Vision and Pattern Recognition},
  year={2015},
  url={https://arxiv.org/abs/1512.00567v3}
}

@misc{PapersWithCode_InceptionV2,
  title={Inception v2},
  howpublished={\url{https://paperswithcode.com/method/inception-v2}},
  note={Accessed: 18-11-2023},
  year={2023}
}

@article{Szegedy2016RethinkingTI,
  title={Rethinking the Inception Architecture for Computer Vision},
  author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Z. Wojna},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  doi={10.1109/CVPR.2016.308},
  url={https://dx.doi.org/10.1109/CVPR.2016.308},
}


@article{He2015,
  title={Deep Residual Learning for Image Recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal={arXiv preprint arXiv:1512.03385},
  year={2015},
  url={https://arxiv.org/abs/1512.03385}
}
